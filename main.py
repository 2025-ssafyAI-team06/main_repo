# main.py
"""
ì›”ë“œì»µ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
"""

from utils import (
    set_api_key,
    load_csv_data,
    run_sql_query,
    format_dataframe_result,
    print_pipeline_step
)
from services import (
    classify_query_category,
    generate_sql_from_query,
    generate_natural_answer,
    is_supported_category
)
from prompts import CATEGORY_MESSAGES

import os
import json
import random

from dotenv import load_dotenv

from langchain_chroma import Chroma
from langchain_upstage import UpstageEmbeddings
from langchain_upstage import ChatUpstage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from serpapi import GoogleSearch

load_dotenv()

UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
SERPAPI_API_KEY = os.getenv("SERPAPI_API_KEY")

# ChromaDB ë¶ˆëŸ¬ì˜¤ê¸°
DB_NAME = os.getenv("DB_NAME")
DB_PATH = os.getenv("DB_PATH")

# ì„ë² ë”©
passage_embedder = UpstageEmbeddings(model="embedding-passage")
query_embedder = UpstageEmbeddings(model="embedding-query")

spot_store = Chroma(
                collection_name=DB_NAME,
                embedding_function=passage_embedder,
                persist_directory=DB_PATH
            )


# ë§Œì•½ ~ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜. ë¼ê³  í•œë‹¤ë©´? -> ë¶„ê¸° ì²˜ë¦¬ í•„ìš”!
def intent_classification(user_question):
    system_prompt = \
    """
    
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì•„ë˜ ë‘ ê°€ì§€ì˜ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³ , í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.

    ì˜ë„:
    1. íŠ¹ì • ì¥ì†Œì˜ ìœ„ì¹˜(ì£¼ì†Œ, ìœ„ì¹˜ ì„¤ëª… ë“±)ë¥¼ ë¬»ëŠ” ì§ˆë¬¸
    2. íŠ¹ì • ì¥ì†Œ ê·¼ì²˜ì˜ ë§›ì§‘/ê´€ê´‘ì§€/ìˆ™ì†Œ ë“± ì£¼ë³€ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë‹¬ë¼ëŠ” ì§ˆë¬¸
    
    ê²½ê¸°ì¥ ì´ë¦„ ëª¨ìŒ:
    {{
        ë£¨ë©˜ í•„ë“œ: Lumen Field,
        ë¦¬ë°”ì´ìŠ¤ ìŠ¤íƒ€ë””ì›€: Leviâ€™s Stadium,
        ì†Œí”¼ ìŠ¤íƒ€ë””ì›€: SoFi Stadium,
        ì—ì´í‹°ì•¤í‹° ìŠ¤íƒ€ë””ì›€: AT&T Stadium,
        ì—”ì•Œì§€ ìŠ¤íƒ€ë””ì›€: NRG Stadium,
        ì• ë¡œìš°í—¤ë“œ ìŠ¤íƒ€ë””ì›€: Arrowhead Stadium,
        ë§ì»¨ íŒŒì´ë‚¸ì…œ ìŠ¤íƒ€ë””ì›€: Lincoln Financial Field,
        ë©”ë¥´ì„¸ë°ìŠ¤ ë²¤ì¸  ìŠ¤íƒ€ë””ì›€: Mercedes Benz Stadium,
        í•˜ë“œë¡ ìŠ¤íƒ€ë””ì›€: Hard Rock Stadium,
        ë©§ë¼ì´í”„ ìŠ¤íƒ€ë””ì›€: MetLife Stadium,
        ì§ˆë ˆíŠ¸ ìŠ¤íƒ€ë””ì›€: Gillette Stadium,
        ì•„í¬ë¡  ìŠ¤íƒ€ë””ì›€: Estadio Akron,
        BC í”Œë ˆì´ìŠ¤: BC Place,
        BMO í•„ë“œ: BMO Field
    }}

    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì½ê³ ,
    1) intentëŠ” ë°˜ë“œì‹œ 1, 2 ì¤‘ í•˜ë‚˜ë§Œ ë‹µí•˜ì„¸ìš”.
    2) intentê°€ 1ì´ë¼ë©´, keywordsë¡œ íŠ¹ì • ì¥ì†Œë§Œ ì˜ì–´ë¡œ ë°”ê¿”ì„œ ì¶”ì¶œí•˜ê³ , field_nameì€ ì‚­ì œí•´ì£¼ì„¸ìš”.
    3) intentê°€ 2ì´ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ê²½ê¸°ì¥ ì´ë¦„ì´ ìˆë‹¤ë©´, field_nameìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. field_nameì´ í•œêµ­ì–´ë¼ë©´ ê²½ê¸°ì¥ ì´ë¦„ ëª¨ìŒì„ ì°¸ê³ í•´ì„œ field_nameë§Œ ì˜ì–´ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.
    4) intentê°€ 2ì´ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ê²½ê¸°ì¥ ì´ë¦„ì´ ì—†ë‹¤ë©´, field_nameì€ Noneì…ë‹ˆë‹¤.
    4) intentê°€ 2ë¼ë©´, keywordsëŠ” ìµœëŒ€ 3ê°œë§Œ ì¡´ì¬í•©ë‹ˆë‹¤.
    5) JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

    """
    user_prompt = \
    """
    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

    <<<Output Format>>>
    `{{intent: <1 or 2>,
     keywords: <comma-separated keywords>,
     field_name: <field_name or None>}}`
    """

    # llm
    llm = ChatUpstage(model="solar-mini",
                      temperature=0)

    intent_prompt = ChatPromptTemplate.from_messages(
        messages=[
            (
                "system",
                system_prompt
            ),
            (
                "user",
                user_prompt
            )
        ],
    )

    chain = intent_prompt | llm | StrOutputParser()
    intent_response = chain.invoke({"user_question": user_question})
    print(intent_response)
    return json.loads(intent_response)


# documentsëª¨ìŒì—ì„œ ì›í•˜ëŠ” docs ì°¾ê¸°
def search_answer(response):
    field_name = response["field_name"]

    # ì¿¼ë¦¬ìš© Upstage ì„ë² ë”© ì‚¬ìš©í•˜ê¸° -> ìœ„í‚¤ë…ìŠ¤
    keywords_vector = query_embedder.embed_query(response["keywords"])

    # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•´ì„œ ê°€ì¥ ìœ ì‚¬í•œ 5ê°œì˜ ë¬¸ì„œ ë°˜í™˜í•˜ê¸°
    results = spot_store.similarity_search_by_vector(
        keywords_vector,
        k=5,
        filter={"near_field": field_name}
    )
    return results


# ì‘ë‹µ ìƒì„±í•˜ê¸°
def generate_recommendation_response(filtered_document, user_question):
    context = {
        "name": filtered_document.metadata.get("name"),
        "website": filtered_document.metadata.get("website"),
        "tripadvisor": filtered_document.metadata.get("tripadvisor_url"),
        "address": filtered_document.metadata.get("address"),
        "summary": filtered_document.metadata.get("summary")
    }

    website = context["website"]
    tripadvisor = context["tripadvisor"]

    # LLMì—ê²Œ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­
    system_prompt = \
    """
    ê´€ê´‘ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ê´€ê´‘ì§€ì— ëŒ€í•œ ì¶”ì²œ ë‚´ìš©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    """

    user_prompt = \
    """
    ì•„ë˜ ì¡°ê±´ì„ ì°¸ì¡°í•´ì„œ í˜•ì‹ì— ë”°ë¼ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”
    ì¡°ê±´: [CONDITION]

    ê´€ê´‘ì§€ ì •ë³´ê°€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.
    {context}

    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

    [CONDITION]
    1. ê´€ê´‘ì§€ ì •ë³´ì˜ summaryë¥¼ í™•ì¸í•˜ê³  ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ summaryë¡œ ë°”ê¿”ì„œ ë³´ì—¬ì£¼ì„¸ìš”.
    2. websiteì— ëŒ€í•œ ë‚´ìš©ì´ ì—†ë‹¤ë©´ ë³´ì—¬ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.
    3. tripadvisorì— ëŒ€í•œ ë‚´ìš©ì´ ì—†ë‹¤ë©´ ë³´ì—¬ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.

    <<<Output Format>>>
    ```
    ### name

    - **ì›¹ì‚¬ì´íŠ¸**: {website}
    - **[íŠ¸ë¦½ì–´ë“œë°”ì´ì €]({tripadvisor})**
    - **ì£¼ì†Œ**: address
    - **ìš”ì•½**:
        summary
    ```
    """
    # llm
    llm = ChatUpstage(model="solar-mini",
                      temperature=0.56)

    answer_generation_prompt = ChatPromptTemplate.from_messages(
        messages=[
            (
                "system",
                system_prompt
            ),
            (
                "user",
                user_prompt
            )
        ],
    )

    chain = answer_generation_prompt | llm | StrOutputParser()
    raw_answer = chain.invoke({"context": context, "website": website, "tripadvisor": tripadvisor, "user_question": user_question})
    return raw_answer

# Web search
def use_web_search(user_question):
    params = {
        "engine": "google",
        "q": user_question,
        "api_key": SERPAPI_API_KEY
    }

    search = GoogleSearch(params)
    search_result = search.get_dict()
    print(search_result)

    if search_result["knowledge_graph"]:
        description = search_result["knowledge_graph"].get("description")
        address = search_result["knowledge_graph"].get("address")

        result = {"description": description,
                  "address": address}
        return result

    else:
        return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."


# íŠ¹ì • ê´€ê´‘ì§€ì— ëŒ€í•œ ë‹µë³€
def generate_location_response(search_result, response, user_question):

    spot_name = response["keywords"]

    # LLMì—ê²Œ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­
    system_prompt = \
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì½ê³  ê´€ê´‘ì§€ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ê´‘ì§€ì— ëŒ€í•œ ë‚´ìš©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    """

    user_prompt = \
    """
    ì•„ë˜ ì¡°ê±´ì„ ì°¸ì¡°í•´ì„œ í˜•ì‹ì— ë”°ë¼ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”
    ì¡°ê±´: [CONDITION]

    ê´€ê´‘ì§€ëª…: {spot_name}
    êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼: {search_result}

    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

    [CONDITION]
    1. ë‹µë³€ì€ í•´ë‹¹ ê´€ê´‘ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ê² ë‹¤ëŠ” ë¶„ìœ„ê¸°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
    2. êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ì•ˆì˜ descriptionì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ summaryë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
    3. ì£¼ì†ŒëŠ” êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ ì•ˆì˜ addressë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    4. nameì€ ê´€ê´‘ì§€ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    <<<Output Format>>>
    ```
    ### name
    - ì£¼ì†Œ: address

    summary
    ```
    """

    # llm
    llm = ChatUpstage(model="solar-mini",
                      temperature=0.56)

    answer_generation_prompt = ChatPromptTemplate.from_messages(
        messages=[
            (
                "system",
                system_prompt
            ),
            (
                "user",
                user_prompt
            )
        ],
    )

    chain = answer_generation_prompt | llm | StrOutputParser()
    raw_answer = chain.invoke({"spot_name": spot_name, "search_result": search_result, "user_question": user_question})
    return raw_answer



def run_worldcup_analysis_pipeline(user_query: str, csv_path: str) -> str:
    """
    ì›”ë“œì»µ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        user_query (str): ì‚¬ìš©ì ì§ˆë¬¸
        csv_path (str): CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        str: ìµœì¢… ì‘ë‹µ ë˜ëŠ” None
    """
    # 1. CSV ë°ì´í„° ë¡œë“œ
    df = load_csv_data(csv_path)
    
    # 2. ì¿¼ë¦¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category = classify_query_category(user_query)
    print_pipeline_step("ğŸ“‚ ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬:", category)
    
    # 3. ì§€ì›ë˜ëŠ” ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
    if not is_supported_category(category):
        print(CATEGORY_MESSAGES["unsupported"])
        return None
    
    # 4. SQL ì¿¼ë¦¬ ìƒì„±
    sql_query = generate_sql_from_query(user_query, df)
    print_pipeline_step("ğŸ“„ ìƒì„±ëœ SQL:", f"\n{sql_query}")
    
    # 5. SQL ì‹¤í–‰
    df_result = run_sql_query(sql_query, df)
    print_pipeline_step("ğŸ“Š SQL ì‹¤í–‰ ê²°ê³¼:", f"\n{df_result}")
    
    # 6. ìµœì¢… ìì—°ì–´ ì‘ë‹µ ìƒì„±
    sql_result_str = format_dataframe_result(df_result)
    final_answer = generate_natural_answer(user_query, sql_result_str)
    print_pipeline_step("ğŸ—£ï¸ ìµœì¢… ì‘ë‹µ:", f"\n{final_answer}")
    
    return final_answer

def categoryOne(user_question):
    user_question = "ë£¨ë©˜ í•„ë“œ ê·¼ì²˜ ë§›ì§‘ ì•Œë ¤ì¤˜"
    response = intent_classification(user_question)

    if response["intent"] == 1:
        # keywordë¡œ ì›¹ì„œì¹˜í•˜ê¸°
        print("ì›¹ ì„œì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        search_result = use_web_search(response["keywords"])

        raw_response = generate_location_response(search_result, response, user_question)
        ai_answer = raw_response.strip("```")
        print(ai_answer)
        return ai_answer


    elif response["intent"] == 2:
        print("DBë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        documents = search_answer(response)
        # ë©”íƒ€ ë°ì´í„° ì´ìš©í•´ì„œ ì¡°ê¸ˆ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ê¸°
        keyword_list = response["keywords"].split(", ")

        # í•œ ë²ˆ ë” ê±°ë¥´ê¸°
        filtered_docs = {}

        for document in documents:
            for keyword in keyword_list:
                if keyword in document.metadata.get("about_rank", ""):
                    name = document.metadata.get("name")
                    if name not in filtered_docs:
                        filtered_docs[name] = document

        # í•œë²ˆ ë” ê±¸ëŸ¬ì§„ ê²ƒì´ ì—†ë‹¤ë©´
        if not filtered_docs:
            print("í‚¤ì›Œë“œë¡œ ì •í™•í•œ ë¬¸ì„œ í•„í„°ë§ ì‹¤íŒ¨")
            for document in documents:
                name = document.metadata.get("name")
                if name not in filtered_docs:
                    filtered_docs[name] = document

        filtered_docs_list = [filtered_docs[name] for name in filtered_docs]

        # ê±°ë¥¸ ê²ƒ ì¤‘ì— ëœë¤ìœ¼ë¡œ 2ê°œ ë½‘ê¸°
        selected_docs = random.sample(filtered_docs_list, min(2, len(filtered_docs_list)))

        responses = []

        for doc in selected_docs:
            raw_response = generate_recommendation_response(doc, user_question)
            response = raw_response.strip("```")
            responses.append(response)

        # ë‹µë³€ ìƒì„±í•˜ê¸°
        ai_answer = "\n\n".join(responses)
        print(ai_answer)
        return ai_answer

def create_next_query(category,user_query):
    print("category : ",category)
    if category == "1":
      print("ìœ í˜•1")
      categoryOne(user_query)
    elif category == "2":
      print("ìœ í˜•2")
    elif category == "3":
      return run_worldcup_analysis_pipeline(user_query,"./matches_1930_2022.csv")
    elif category == "4":
      print("ìœ í˜•4")
    elif category == "5":
      print("ìœ í˜•5")
    else:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # API í‚¤ ì„¤ì •
    set_api_key()
    
    # ì˜ˆì‹œ ì‹¤í–‰
    user_query = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    # csv_path = "./matches_1930_2022.csv"

    category = classify_query_category(user_query)
    print_pipeline_step("ğŸ“‚ ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬:", category)

    result = create_next_query(category,user_query)
    
    return result

if __name__ == "__main__":
    main()